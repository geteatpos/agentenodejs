const express = require('express');
const twilio = require('twilio');
const WebSocket = require('ws');
const http = require('http');
const OpenAI = require('openai');
const fs = require('fs');
const ffmpeg = require('fluent-ffmpeg');
const ffmpegStatic = require('ffmpeg-static');
const axios = require('axios');

require('dotenv').config();

const app = express();
app.use(express.json());

const PORT = process.env.PORT || 3000;
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

// ðŸ”¹ Verificar API Keys antes de iniciar
if (!process.env.OPENAI_API_KEY) {
    console.error("âŒ ERROR: OPENAI_API_KEY no estÃ¡ configurada.");
    process.exit(1);
}

if (!process.env.ELEVENLABS_API_KEY) {
    console.error("âŒ ERROR: ELEVENLABS_API_KEY no estÃ¡ configurada.");
    process.exit(1);
}

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

// ðŸ”¹ Almacenar datos de audio en tiempo real
let audioBuffer = Buffer.alloc(0);

// ðŸŸ¢ WebSocket para recibir audio en tiempo real de Twilio
wss.on('connection', (ws) => {
    console.log("ðŸ”— ConexiÃ³n WebSocket establecida con Twilio Media Stream");

    ws.on('message', async (data) => {
        console.log("ðŸŽ™ï¸ Recibiendo audio en tiempo real... (chunk de datos)");
        audioBuffer = Buffer.concat([audioBuffer, data]);
    });

    ws.on('close', async () => {
        console.log("ðŸ”Œ ConexiÃ³n WebSocket cerrada, procesando audio...");

        if (audioBuffer.length > 0) {
            console.log(`ðŸ” TamaÃ±o del audio recibido: ${audioBuffer.length} bytes`);

            // Guardar el audio temporalmente
            const rawAudioPath = './audio.raw';
            fs.writeFileSync(rawAudioPath, audioBuffer);
            console.log(`âœ… Audio guardado en ${rawAudioPath}`);

            // Convertir a WAV
            const wavAudioPath = './audio.wav';

            ffmpeg()
                .setFfmpegPath(ffmpegStatic)
                .input(rawAudioPath)
                .inputFormat('mulaw') // Twilio envÃ­a audio en formato mu-law
                .outputOptions([
                    '-ar 16000', // Convertir a 16 kHz
                    '-ac 1', // Canal mono
                    '-b:a 128k', // Calidad de audio alta
                    '-f wav'
                ])
                .output(wavAudioPath)
                .on('start', (cmd) => console.log(`â–¶ Ejecutando FFmpeg: ${cmd}`))
                .on('error', (err) => console.error("âŒ Error en FFmpeg:", err))
                .on('end', async () => {
                    console.log("ðŸŽ§ Audio convertido, enviando a Whisper...");

                    try {
                        // Transcribir el audio con Whisper
                        const transcription = await openai.audio.transcriptions.create({
                            file: fs.createReadStream(wavAudioPath),
                            model: "whisper-1",
                            language: "es", // Cambiar a "en" si es inglÃ©s
                            response_format: "text"
                        });

                        console.log("ðŸ“ TranscripciÃ³n:", transcription.text);

                        // ðŸ”¥ Generar respuesta en voz con Eleven Labs
                        const respuestaAudio = await generarAudioElevenLabs(transcription.text);
                        if (respuestaAudio) {
                            console.log(`ðŸ“¢ Respuesta generada en: ${respuestaAudio}`);
                        }

                        // Limpiar archivos temporales
                        fs.unlinkSync(rawAudioPath);
                        fs.unlinkSync(wavAudioPath);
                    } catch (error) {
                        console.error("âŒ Error en la transcripciÃ³n:", error);
                    }
                })
                .run();
        } else {
            console.error("âŒ No se recibiÃ³ audio vÃ¡lido.");
        }
    });

    ws.on('error', (err) => {
        console.error("âŒ Error en WebSocket:", err);
    });
});

// ðŸ”¹ FunciÃ³n para generar respuesta en voz con Eleven Labs
async function generarAudioElevenLabs(texto) {
    console.log("ðŸŽ™ï¸ Generando audio con Eleven Labs...");

    try {
        const response = await axios.post(
            'https://api.elevenlabs.io/v1/text-to-speech/2qEjXpSVHAkqHEoF1x8h', // âš ï¸ Reemplaza con tu Voice ID
            {
                text: texto,
                voice_settings: { stability: 0.5, similarity_boost: 0.7 }
            },
            {
                headers: {
                    'Content-Type': 'application/json',
                    'xi-api-key': process.env.ELEVENLABS_API_KEY
                },
                responseType: 'arraybuffer'
            }
        );

        const respuestaAudioPath = './respuesta.mp3';
        fs.writeFileSync(respuestaAudioPath, response.data);
        console.log("âœ… Audio generado y GUARDADO POR MI  como respuesta.mp3");

        return respuestaAudioPath;
    } catch (error) {
        console.error("âŒ Error generando audio en Eleven Labs:", error);
        return null;
    }
}

// ðŸ”¹ Ruta para recibir Twilio Media Stream
app.post('/media-stream', (req, res) => {
    console.log("âœ… Recibida solicitud en /media-stream");

    try {
        const twiml = new twilio.twiml.VoiceResponse();
        twiml.connect().stream({
            url: `wss://${req.hostname}/ws`,
        });

        console.log("ðŸ“¡ Enviando TwiML a Twilio...");
        res.type('text/xml');
        res.send(twiml.toString());
    } catch (error) {
        console.error("âŒ Error en /media-stream:", error);
        res.status(500).send("Error en Media Stream");
    }
});

// ðŸ”¹ Escuchar en el mismo servidor Express
server.listen(PORT, () => {
    console.log(`ðŸš€ Servidor Express y WebSocket corriendo en http://localhost:${PORT}`);
});
